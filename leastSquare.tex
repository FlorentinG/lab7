This section tries to fit the data given with the least squares method. The function used to fit the data is :

$$y(t) = c_1 + c_2e^{\alpha t}+\sum_{k=1}^n (a_k cos(\frac{2\pi kt}{12}) + b_k sin(\frac{2\pi kt}{12}))$$

The problem consists thus of finding $c_1$, $c_2$, $a_k$ and $b_k$ that minimize $||Ax-b||_2$ where:

$$A = \left(\begin{array}{cccccccc}
1 & e^{\alpha t_1} & cos(\frac{2\pi k_1t_1}{12}) & \dots & cos(\frac{2\pi k_nt_1}{12}) & sin(\frac{2\pi k_1t_1}{12}) & \dots & sin(\frac{2\pi k_nt_1}{12}) \\ 
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\ 
1 & e^{\alpha t_m} & cos(\frac{2\pi k_1t_m}{12})& \dots & cos(\frac{2\pi k_nt_m}{12}) & sin(\frac{2\pi k_1t_m}{12}) & \dots & sin(\frac{2\pi k_nt_m}{12})
\end{array} \right)$$

$$x=(c_1 \: c_2 \: a_1 \: \dots \: a_n \: b_1 \: \dots b_n)^T$$

And $b \in \mathbb{R}^{m\times 1}$ is the vector containing the data at times $t_i$ with $i=1...m$.

This problem can be solved using the least squares method. To do this, we are going to use the QR-factorization, i.e. the fact that:
$$A=QR$$

With $Q$ an orthogonal matrix and $R$ upper triangular. Indeed, to minimize the norm of the residual, we know that we have to solve the normal equations :
$$A^TAx=A^Tb$$

But using QR-factorization allows us to say (the proof can be found in the course notes) : 
$$Rx=Q^Tb$$

The Matlab code used to solve the problem can be found at the end of this report. We define the residual as $\text{res } = A\textbf{x}-b$ where $\textbf{x}$ is the solution of the normal equations.


For $n=1$, here are the values obtained for the parameters :

\begin{center}
\begin{tabular}{|c|c|}
\hline 
$c_1$ & 2.5581 \\ 
\hline 
$c_2$ & 334.9964 \\ 
\hline 
$a_1$ & -1.7186 \\ 
\hline 
$b_1$ & 2.3581 \\ 
\hline 
\end{tabular} 
\end{center}

And the computed norm of the residual is :
$$||\text{res }(n=1)||_2=15.2036$$

For $n=2$, the parameters are the following : 

\begin{center}
\begin{tabular}{|c|c|}
\hline 
$c_1$ & 2.7340 \\ 
\hline 
$c_2$ & 334.8298 \\ 
\hline 
$a_1$ & -1.7185 \\ 
\hline 
$a_2$ & 0.8382 \\
\hline
$b_1$ & 2.3579 \\ 
\hline 
$b_2$ & -0.0345\\
\hline
\end{tabular} 
\end{center}

And the norm of the residual is :
$$||\text{res }(n=2)||_2=11.3936$$

And finally, for $n=3$, these are the parameters : 

\begin{center}
\begin{tabular}{|c|c|}
\hline 
$c_1$ & 2.7665 \\ 
\hline 
$c_2$ & 334.7990 \\ 
\hline 
$a_1$ & -1.7185 \\ 
\hline 
$a_2$ & 0.8382 \\
\hline
$a_3$ & 0.1094\\
\hline
$b_1$ & 2.3579 \\ 
\hline 
$b_2$ & -0.0345\\
\hline
$b_3$ & -0.0568\\
\hline
\end{tabular} 
\end{center}

And the norm of the residual is :
$$||\text{res }(n=3)||_2=11.2972$$
It is important to note that the norm of the residual decreases as we increase $n$. That is to be expected since when we increase $n$ by one, we allow two new degrees of freedom. Thus, it is not possible to obtain a "worse" residual with a higher $n$. In the worst case scenario, the two new basis functions do not increase the quality of the fitting and then the corresponding coefficients would be zero. The residuals would then be equal.

Figure \ref{lsp} shows the fitting for $n=3$. We can see that it is relatively good. The $'\times'$ are the data points and the red curve is the fitting.

\begin{figure}
\begin{center}
\includegraphics[scale=0.7]{lsp.eps}
\caption{Fitting of the data for $n=3$}
\label{lsp}
\end{center}
\end{figure}
\FloatBarrier